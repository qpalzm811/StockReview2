import logging
import pandas as pd
from datetime import datetime
from typing import List, Dict, Any
from PyQt6.QtCore import QObject, pyqtSignal

from model.data_nexus import DataNexus
from model.db_manager import DBManager
from model.pattern_recognizer import PatternRecognizer
import os
import concurrent.futures

def analyze_stock_worker(symbol: str, df_stock: pd.DataFrame, stock_name: str) -> List[Dict]:
    """
    å•åªè‚¡ç¥¨åˆ†ææ ¸å¿ƒé€»è¾‘ (Worker Task - MultiProcessing).
    Pure Data Processing.
    """
    try:
        # --- [Filter] Dynamic Quality Check (Layer 2) ---
        from model.data_filter import DataFilter
        if not DataFilter.check_quality(df_stock, min_bars=60):
                return []
        
        # --- [Factor & Pattern Engine] ---
        from model.technical_factors import TechnicalFactors
        from model.complex_patterns import ComplexPatterns
        from model.wyckoff_math import WyckoffMath
        
        # 1. Calculate Basic Factors
        df_stock = TechnicalFactors.add_all_factors(df_stock)
        
        # 2. Identify Wyckoff Math Patterns
        df_stock = WyckoffMath.apply(df_stock)
        
        # 3. Identify Complex Patterns
        df_stock = ComplexPatterns.detect_patterns(df_stock)
        
        # 4. Check Signals (Last Bar)
        if df_stock.empty: return []
        last_bar = df_stock.iloc[-1]
        last_close = float(last_bar['close'])
        
        found_signals_tuples = []
        
        # --- Classic Patterns ---
        if last_bar.get('pattern_double_bottom', 0) == 1:
            found_signals_tuples.append(('W-Bottom', 'åŒåº•çªç ´'))
            
        if last_bar.get('pattern_triangle', 0) == 1:
            found_signals_tuples.append(('Triangle', 'æ”¶æ•›ä¸‰è§’å½¢'))
            
        if last_bar.get('pattern_vcp', 0) == 1:
                found_signals_tuples.append(('VCP', 'æ³¢åŠ¨æ”¶ç¼©(VCP)'))
                
        # Check Factor Signals
        if last_bar.get('signal_kdj_rsi', 0) == 1:
            found_signals_tuples.append(('Resonance', 'KDJ+RSIå…±æŒ¯'))
            
        if last_bar.get('signal_macd_cross', 0) == 1:
            found_signals_tuples.append(('MACD-Cross', 'MACDé‡‘å‰/å¤šå¤´'))
        
        # [Aggregation Logic]
        # 1. Calculate Score
        score, score_desc = TechnicalFactors.calculate_composite_score(df_stock)
        
        # 2. Stricter Resonance Filtering (User Request: Less noise, higher win rate)
        num_signals = len(found_signals_tuples)
        
        is_valid = False
        if num_signals >= 2:
            # Resonance: Multiple technical signals validating each other
            is_valid = True
        elif num_signals == 1 and score >= 70:
            # Single pattern but very strong background trend/composite score
            is_valid = True
        elif num_signals == 0 and score >= 90:
            # Exceptionally top robust score even without specific pattern
            is_valid = True

        if is_valid:
            
            # Combine Info
            if found_signals_tuples:
                combined_info = " + ".join([desc for _, desc in found_signals_tuples])
                primary_type = "Multi-Signal" if num_signals > 1 else found_signals_tuples[0][0]
                
                # Prepend Resonance tag for UI highlight if multiple
                if num_signals >= 2:
                    primary_type = f"ğŸ”¥ {primary_type}"
            else:
                combined_info = "æå¼ºè¶‹åŠ¿ (æ— ç‰¹å®šå½¢æ€)"
                primary_type = "ğŸ”¥ High Score"
            
            return [{
                "symbol": symbol,
                "name": stock_name,
                "type": primary_type,
                "price": last_close,
                "info": combined_info,
                "score": score,
                "score_desc": score_desc
            }]
            
        return []
        
    except Exception:
        return []

class ScannerSignals(QObject):
    """
    æ‰«ææœåŠ¡ä¿¡å·å®šä¹‰.
    """
    progress = pyqtSignal(int, int) # (å½“å‰, æ€»æ•°)
    signal_found = pyqtSignal(dict) # ä¿¡å·è¯¦æƒ…
    finished = pyqtSignal()         # å®Œæˆ
    error = pyqtSignal(str)         # é”™è¯¯ä¿¡æ¯
    log = pyqtSignal(str)           # æ—¥å¿—ä¿¡æ¯

class ScannerService(QObject):
    """
    æ™ºèƒ½æ‰«ææœåŠ¡ (Scanner Service).
    
    è´Ÿè´£è°ƒåº¦å…¨å¸‚åœºæ‰«æä»»åŠ¡.
    [Performance]: Batch IO Mode correctly implemented.
    """
    
    def __init__(self, db_manager: DBManager, data_nexus: DataNexus) -> None:
        super().__init__()
        self.db = db_manager
        self.nexus = data_nexus
        self.recognizer = PatternRecognizer()
        self.signals = ScannerSignals()
        self._is_running = False

    def run_scan(self, market: str = 'A') -> None:
        """
        æ‰§è¡Œæ‰«æ (Execute Scan) [Multithreaded Turbo].
        
        [Performance Optimization]: 
        1. Vectorized Batch IO (DuckDB) -> Fast Read.
        2. Parallel Processing (Thread Pool 32 Threads) -> Fast Calc.
        """
        self._is_running = True
        
        # [Performance] Profiler Start
        profiler = None
        try:
            from pyinstrument import Profiler
            profiler = Profiler()
            profiler.start()
            self.signals.log.emit("æ€§èƒ½åˆ†æå™¨(pyinstrument) å·²å¯åŠ¨ï¼Œå°†åœ¨æ‰«æç»“æŸåç”ŸæˆæŠ¥å‘Š...")
        except ImportError:
            self.signals.log.emit("æç¤º: æœªå®‰è£… pyinstrumentï¼Œæ— æ³•ç”Ÿæˆæ€§èƒ½åˆ†ææŠ¥å‘Š.")

        self.signals.log.emit(f"å¼€å§‹æ‰«æå¸‚åœº: {market} (Extreme Mode 32 Threads)")
        
        try:
            # 1. è·å–è‚¡ç¥¨åˆ—è¡¨
            stock_list = self.db.fetch_stock_list()
            
            if stock_list.empty:
                self.signals.log.emit("æœ¬åœ°æ•°æ®åº“ä¸ºç©ºï¼Œè¯·å…ˆç‚¹å‡»[åˆ·æ–°è‚¡ç¥¨åˆ—è¡¨]å’Œ[ä¸€é”®æ›´æ–°å†å²æ•°æ®].")
                self.signals.finished.emit()
                return
                
            total_stocks = len(stock_list)
            self.signals.log.emit(f"è·å–åˆ° {total_stocks} åªè‚¡ç¥¨ï¼Œå¼€å§‹æ‰¹é‡åˆ†æ...")
            
            # 2. æ‰¹é‡å¤„ç†
            # [Optimization] Increased Batch Size for better DuckDB Vectorization (User Request)
            BATCH_SIZE = 500
            all_symbols = stock_list['symbol'].tolist()
            
            # Name Lookup Map for speed
            name_map = dict(zip(stock_list['symbol'], stock_list['name']))
            
            processed_count = 0
            total_market_data_loaded = 0
            
            # [Upgrade] Multi-Processing Executor
            # Bypass GIL -> 100% CPU
            cpu_cores = os.cpu_count() or 16
            self.executor = concurrent.futures.ProcessPoolExecutor(max_workers=cpu_cores)
            self.signals.log.emit(f"æ ¸åŠ¨åŠ›å¼•æ“(Multi-Processing)å·²å¯åŠ¨ï¼Œè°ƒç”¨æ ¸å¿ƒæ•°: {cpu_cores}")
            
            try:
                # [Memory Optimization] Collect all signals, write ONCE at end.
                all_signals = [] 
                
                for i in range(0, total_stocks, BATCH_SIZE):
                    if not self._is_running:
                        break
                        
                    batch_symbols = all_symbols[i : i + BATCH_SIZE]
                    
                    try:
                        # 3. æ‰¹é‡è·å–å†å²æ•°æ® (Vectorized IO - Main Thread)
                        batch_df = self.db.fetch_history_batch(batch_symbols, days=365)
                        
                        if batch_df.empty:
                            processed_count += len(batch_symbols)
                            self.signals.progress.emit(processed_count, total_stocks)
                            continue
                            
                        total_market_data_loaded += len(batch_df)
                        
                        # 4. å¹¶è¡Œåˆ†æ (Parallel Analysis - MP)
                        grouped = batch_df.groupby('symbol')
                        
                        futures = []
                        for symbol, df_stock in grouped:
                            if not self._is_running: break
                            
                            # Submit Task to Process Pool
                            # Must use top-level function
                            f = self.executor.submit(
                                analyze_stock_worker, 
                                symbol, 
                                df_stock.copy(), 
                                name_map.get(symbol, "Unknown")
                            )
                            futures.append(f)
                            
                        # Collect Results (Main Thread)
                        
                        for f in concurrent.futures.as_completed(futures):
                            if not self._is_running:
                                self.executor.shutdown(wait=False, cancel_futures=True)
                                break
                                
                            try:
                                found_signals = f.result()
                                if found_signals:
                                    for sig in found_signals:
                                        # UI Update (Immediate)
                                        self.signals.signal_found.emit(sig)
                                        # Buffer for Memory
                                        all_signals.append(sig)
                            except Exception as e:
                                pass
                        
                        # [Optimization] No frequent writes. Pure Memory.
                        
                    except Exception as e:
                         pass
                    
                    try:
                        processed_count += len(batch_symbols)
                        if self._is_running:
                             self.signals.progress.emit(processed_count, total_stocks)
                    except RuntimeError:
                        break # App closed
            finally:
                if self.executor:
                    self.executor.shutdown(wait=True)
                    self.executor = None
            
            # [Final Write] One IO Transaction
            if all_signals and self._is_running:
                try:
                    self.signals.log.emit(f"æ­£åœ¨å°† {len(all_signals)} æ¡ä¿¡å·æ‰¹é‡å†™å…¥æ•°æ®åº“...")
                except RuntimeError: pass
                self.db.batch_insert_signals(all_signals)
                
            if total_market_data_loaded == 0:
                try: self.signals.log.emit("è­¦å‘Š: æœªæ‰«æåˆ°ä»»ä½•æœ‰æ•ˆè¡Œæƒ…æ•°æ®! è¯·ç‚¹å‡»[ä¸€é”®æ›´æ–°å†å²æ•°æ®]ä¸‹è½½æ•°æ®.")
                except: pass
            else:
                try: self.signals.log.emit("å…¨å¸‚åœºæ‰«æå®Œæˆ.")
                except: pass
            
        except Exception as e:
            try: self.signals.log.emit(f"æ‰«ææœåŠ¡å‡ºé”™: {e}")
            except: pass
        finally:
            # [Performance] Profiler Stop
            if profiler:
                try:
                    profiler.stop()
                    os.makedirs('logs', exist_ok=True)
                    report_path = os.path.join('logs', 'scan_performance.html')
                    profiler.write_html(report_path)
                    try: self.signals.log.emit(f"æ€§èƒ½åˆ†ææŠ¥å‘Šå·²ä¿å­˜è‡³ä¸“ç”¨ç›®å½•: {report_path}")
                    except: pass
                except Exception: pass

            self._is_running = False
            try:
                self.signals.finished.emit()
            except RuntimeError:
                pass




    def save_signal(self, data: Dict[str, Any]) -> None:
        """ä¿å­˜ä¿¡å·åˆ°æ•°æ®åº“."""
        try:
            con = self.db.get_connection()
            # SQL Keywords Uppercase
            con.execute("""
                INSERT INTO signals (symbol, signal_date, signal_type, confidence, description)
                VALUES (?, current_timestamp, ?, ?, ?)
            """, (data['symbol'], data['type'], 0.8, data['info']))
            con.close()
        except Exception as e:
            print(f"DB Error saving signal: {e}")

    def stop(self) -> None:
        """
        [Safety] åœæ­¢æ‰«æ (Force Stop).
        ç«‹å³ç»ˆæ­¢æ‰€æœ‰åå°çº¿ç¨‹.
        """
        self._is_running = False
        if hasattr(self, 'executor') and self.executor:
             self.executor.shutdown(wait=False, cancel_futures=True)
